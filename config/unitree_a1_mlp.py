config = dict(
    env_id="A1-v1",
    num_workers=16,
    algo="ppo",
    name="mlp_dr_v1_e0.1_y0_z0.1_sv0.005",
    total_timesteps=int(1e7),
    create_env_kwargs=dict(
        obs_keys=["HistoricSensorWrapper(IMU)", "HistoricSensorWrapper(LastAction)",
                  "HistoricSensorWrapper(MotorAngle)"],
        reward_scale=1.0,
        scale_action=True,
        info_keywords=("total_distance", "total_drift", "total_shake", "total_energy"),
        kwargs=dict(task="simple_forward",
                    enable_randomizer=True,
                    enable_terrain_random=False,
                    task_kwargs=dict(energy_weight=0.1, drift_weight=0.0, shake_weight=0.1,
                                     survive_weight=0.005)),
    ),
    policy_type="mlp",
    policy=dict(
        hidden_size=128,
    ),
    train=dict(
        nminibatches=16,
        noptepochs=10,
        n_steps=1024,
        learning_rate=1e-4,
        use_wandb=True,
    ),
)
